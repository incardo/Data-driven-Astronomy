{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33df1641-c5e4-45ce-84ab-db6b2d29eec0",
   "metadata": {},
   "source": [
    "# Week 5: Building a regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4692f812-6788-4b90-8ce4-b08f2652fa48",
   "metadata": {},
   "source": [
    "In this activity, we're going to use decision trees to determine the redshifts of galaxies from their photometric colours. We'll use galaxies where accurate spectroscopic redshifts have been calculated as our gold standard. We will learn how to assess the accuracy of the decision trees predictions and have a look at validation of our model.\n",
    "\n",
    "We will also have a quick look at how this problem might be approached without using machine learning. This will highlight some of the limitations of the classical approach and demonstrate why a machine learning approach is ideal for this type of problem.\n",
    "\n",
    "If you want to run your code offline, you can download the full NumPy dataset for this activity here.\n",
    "\n",
    "This activity is based on the scikit-learn example on Photometric Redshifts of Galaxies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96597169-4dc1-4797-b3fa-ef0505ec600d",
   "metadata": {},
   "source": [
    "Write a get_features_targets function that splits the training data into input features and their corresponding targets. In our case, the inputs are the 4 colour indices and our targets are the corresponding redshifts.\n",
    "\n",
    "Your function should return a tuple of:\n",
    "\n",
    "features: a NumPy array of dimensions m ⨉ 4, where m is the number of galaxies;\n",
    "targets: a 1D NumPy array of length m, containing the redshift for each galaxy.\n",
    "The data argument will be the structured array described on the previous slide. The u flux magnitudes and redshifts can be accessed as a column with data['u'] and data['redshift'].\n",
    "\n",
    "The four features are the colours u - g, g - r, r - i and i - z. To calculate the first column of features, subtract the u and g columns, like this:\n",
    "\n",
    "\n",
    "print(data['u'] - data['g'])\n",
    "import numpy as np\n",
    "data = np.load('sdss_galaxy_colors.npy')\n",
    "print(data['u'] - data['g'])\n",
    "The features for the first 2 galaxies in the example data should be:\n",
    "\n",
    "[[ 0.31476  0.0571   0.28991  0.07192]\n",
    " [ 1.2002   0.82026  0.45294  0.24665]]\n",
    "And the first 2 targets should be:\n",
    "[ 0.539301   0.1645703] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e24d6c2-3719-4d01-a249-716a8acff160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19.84132, 19.52656, 19.46946, 19.17955, 19.10763, b'QSO', 0.539301, 6.543622e-05)\n",
      "[0.31476 1.2002  1.65941 ... 1.72629 0.23287 0.19067]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load('sdss_galaxy_colors.npy')\n",
    "print(data[0])\n",
    "\n",
    "print(data['u'] - data['g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37c2d56e-33ac-4566-895e-b56881fe1947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(19.84132, 19.52656, 19.46946, 19.17955, 19.10763, b'QSO', 0.539301  , 6.543622e-05),\n",
       "       (19.86318, 18.66298, 17.84272, 17.38978, 17.14313, b'GALAXY', 0.1645703 , 1.186625e-05),\n",
       "       (19.97362, 18.31421, 17.47922, 17.0744 , 16.76174, b'GALAXY', 0.04190006, 2.183788e-05),\n",
       "       ...,\n",
       "       (19.82667, 18.10038, 17.16133, 16.5796 , 16.19755, b'GALAXY', 0.0784592 , 2.159406e-05),\n",
       "       (19.98672, 19.75385, 19.5713 , 19.27739, 19.25895, b'QSO', 1.567295  , 4.505933e-04),\n",
       "       (18.00024, 17.80957, 17.77302, 17.72663, 17.7264 , b'QSO', 0.4749449 , 6.203324e-05)],\n",
       "      dtype=[('u', '<f8'), ('g', '<f8'), ('r', '<f8'), ('i', '<f8'), ('z', '<f8'), ('spec_class', 'S6'), ('redshift', '<f8'), ('redshift_err', '<f8')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd791fa9-1ff3-4725-8641-3a6b95ac62c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('u', 'g', 'r', 'i', 'z', 'spec_class', 'redshift', 'redshift_err')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtype.names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c99120-f805-4e37-8278-b8bbcc9b8283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31476 0.0571  0.28991 0.07192]\n",
      " [1.2002  0.82026 0.45294 0.24665]]\n",
      "[0.539301  0.1645703]\n"
     ]
    }
   ],
   "source": [
    "def get_features_targets(data):\n",
    "    data = np.load('sdss_galaxy_colors.npy')\n",
    "\n",
    "    features = np.zeros((data.shape[0], 4))\n",
    "    features[:, 0] = data['u'] - data['g']\n",
    "    features[:, 1] = data['g'] - data['r']\n",
    "    features[:, 2] = data['r'] - data['i']\n",
    "    features[:, 3] = data['i'] - data['z']\n",
    "    \n",
    "    targets =  data['redshift'] \n",
    "    \n",
    "    return features, targets\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  # load the data\n",
    "  data = np.load('sdss_galaxy_colors.npy')\n",
    "    \n",
    "  # call our function \n",
    "  features, targets = get_features_targets(data)\n",
    "    \n",
    "  # print the shape of the returned arrays\n",
    "  print(features[:2])\n",
    "  print(targets[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b81b2-8c65-46ac-abb7-4924c6931edb",
   "metadata": {},
   "source": [
    "We are now going to use our features and targets to train a decision tree and then make a prediction. We are going to use the DecisionTreeRegressor class from the sklearn.tree module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa677143-c778-4e73-a9af-c74e56b47d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.539301   0.1645703  0.04190006 0.04427702]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# copy in your get_features_targets function here\n",
    "def get_features_targets(data):\n",
    "    data = np.load('sdss_galaxy_colors.npy')\n",
    "\n",
    "    features = np.zeros((data.shape[0], 4))\n",
    "    features[:, 0] = data['u'] - data['g']\n",
    "    features[:, 1] = data['g'] - data['r']\n",
    "    features[:, 2] = data['r'] - data['i']\n",
    "    features[:, 3] = data['i'] - data['z']\n",
    "    targets =  data['redshift'] \n",
    "    \n",
    "    return features, targets\n",
    "\n",
    "# load the data and generate the features and targets\n",
    "data = np.load('sdss_galaxy_colors.npy')\n",
    "features, targets = get_features_targets(data)\n",
    "  \n",
    "# initialize model\n",
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "# train the model\n",
    "dtr.fit(features, targets)\n",
    "\n",
    "# make predictions using the same features\n",
    "predictions = dtr.predict(features)\n",
    "\n",
    "# print out the first 4 predicted redshifts\n",
    "print(predictions[:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd827aa3-73cd-44ed-b228-9bde89decae5",
   "metadata": {},
   "source": [
    "So we trained a decision tree! Great...but how do we know if the tree is actually any good at predicting redshifts?\n",
    "\n",
    "In regression we compare the predictions generated by our model with the actual values to test how well our model is performing. The difference between the predicted values and actual values (sometimes referred to as residuals) can tell us a lot about where our model is performing well and where it is not.\n",
    "\n",
    "While there are a few different ways to characterise these differences, in this tutorial we will use the median of the differences between our predicted and actual values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478160c-74e3-4a95-bcc0-3ce3aed68211",
   "metadata": {},
   "source": [
    "In this problem we will implement the function median_diff. The function should calculate the median residual error of our model, i.e. the median difference between our predicted and actual redshifts.\n",
    "\n",
    "The median_diff function takes two arguments – the predicted and actual/target values. When we use this function later in the tutorial, these will corresponding to the predicted redshifts from our decision tree and their corresponding measured/target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7df791f1-60ad-484d-b8b0-0f88c7b9222e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# write a function that calculates the median of the differences\n",
    "# between our predicted and actual values\n",
    "def median_diff(predicted, actual):\n",
    "    return np.median(abs(predicted-actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcccc96-d6c7-498f-b532-81ce1db02ca6",
   "metadata": {},
   "source": [
    "We previously used the same data for training and testing our decision trees.\n",
    "\n",
    "This gives an unrealistic estimate of how accurate the model will be on previously unseen galaxies because the model has been optimised to get the best results on the training data.\n",
    "\n",
    "The simplest way to solve this problem is to split our data into training and testing subsets:\n",
    "\n",
    "This method of validation is the most basic approach to validation and is called held-out validation. We will use the med_diff accuracy measure and hold-out validation in the next problem to assess the accuracy of our decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b528c34a-37b4-42bd-b20c-e9fa84c57ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median difference: 0.021892\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# paste your get_features_targets function here\n",
    "def get_features_targets(data):\n",
    "    data = np.load('sdss_galaxy_colors.npy')\n",
    "\n",
    "    features = np.zeros((data.shape[0], 4))\n",
    "    features[:, 0] = data['u'] - data['g']\n",
    "    features[:, 1] = data['g'] - data['r']\n",
    "    features[:, 2] = data['r'] - data['i']\n",
    "    features[:, 3] = data['i'] - data['z']\n",
    "    targets =  data['redshift'] \n",
    "    \n",
    "    return features, targets\n",
    "\n",
    "# paste your median_diff function here\n",
    "def median_diff(predicted, actual):\n",
    "    return np.median(abs(predicted-actual))\n",
    "\n",
    "# write a function that splits the data into training and testing subsets\n",
    "# trains the model and returns the prediction accuracy with median_diff\n",
    "def validate_model(model, features, targets):\n",
    "  # split the data into training and testing features and predictions\n",
    "    split = features.shape[0]//2\n",
    "    train_features = features[:split]\n",
    "    test_features = features[split:]\n",
    "    train_targets = targets[:split]\n",
    "    test_targets = targets[split:]\n",
    "    \n",
    "  # train the model\n",
    "    dtr = DecisionTreeRegressor()\n",
    "    dtr.fit(train_features, train_targets)\n",
    "    \n",
    "  # get the predicted_redshifts\n",
    "    predictions = dtr.predict(test_features)\n",
    "    \n",
    "    # use median_diff function to calculate the accuracy\n",
    "    return median_diff(test_targets, predictions)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = np.load('sdss_galaxy_colors.npy')\n",
    "    features, targets = get_features_targets(data)\n",
    "\n",
    "    # initialize model\n",
    "    dtr = DecisionTreeRegressor()\n",
    "\n",
    "    # validate the model and print the med_diff\n",
    "    diff = validate_model(dtr, features, targets)\n",
    "    print('Median difference: {:f}'.format(diff))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd1b4c0-74ce-4c6b-8794-86655991cd58",
   "metadata": {},
   "source": [
    "You can see how the decision is made at each node as well as the number of samples which reach that node. We won't go through how to make these plots in the tutorial, but you can download a demo script and data to try at home.\n",
    "\n",
    "The median of differences of  \n",
    "≈\n",
    "0.02\n",
    " . This means that half of our galaxies have a error in the prediction of  \n",
    "<\n",
    "0.02\n",
    " , which is pretty good. One of the reason we chose the median of differences as our accuracy measure is that it gives a fair representation of the errors especially when the distribution of errors is skewed. The graph below shows the distribution of residuals (differences) for our model along with the median and interquartile values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e8e102a-7930-48cd-a0c3-ac9955506089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\incar\\\\Documents\\\\GitHub\\\\Data-driven-Astronomy\\\\week5-decision_tree_redshift'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0b743e8-4955-4044-adc8-5cb5d27dd09f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install update sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03ef6047-9c4f-44f9-9c9c-5290d4d5ae0e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7548/877363897.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mdot_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'u - g'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'g - r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r - i'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'i - z'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_jpg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"decision_tree.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(path, f, prog)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                 \u001b[1;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1810\u001b[1;33m                 \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m             )\n\u001b[0;32m   1812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, path, prog, format)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m                 \u001b[0mfobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1957\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m                 raise InvocationException(\n\u001b[0m\u001b[0;32m   1960\u001b[0m                     'GraphViz\\'s executables not found')\n\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pydotplus as pydotplus\n",
    "from sklearn.tree import DecisionTreeRegressor,export_graphviz\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = np.load('sdss_galaxy_colors.npy')\n",
    "    features, targets = get_features_targets(data)\n",
    "\n",
    "    # Initialize model\n",
    "    dtr = DecisionTreeRegressor(max_depth=3)    # We will come to this input in the next tutorial\n",
    "\n",
    "    # Split the data into training and testing\n",
    "    split_index = int(0.5 * len(features))\n",
    "    train_features = features[:split_index]\n",
    "    train_targets = targets[:split_index]\n",
    "\n",
    "    dtr.fit(train_features, train_targets)\n",
    "\n",
    "    dot_data = export_graphviz(dtr, out_file=None,feature_names=['u - g', 'g - r', 'r - i', 'i - z'])\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    graph.write_jpg(\"decision_tree.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aed7ce-0d49-46d6-83d4-fb447d281843",
   "metadata": {},
   "source": [
    "The number of galaxies we use to train the model has a big impact on how accurate our predictions will be. This is the same with most machine learning methods: the more data that they are trained with, the more accurate their prediction will be.\n",
    "\n",
    "Here is how our median difference changes with training set size:\n",
    "\n",
    "Training galaxies\tmedian_diff\n",
    "50\t0.048\n",
    "500\t0.026\n",
    "5000\t0.023\n",
    "50000\t0.022\n",
    "Understanding how the accuracy of the model changes with sample size is important to understanding the limitations of our model. We are approaching the accuracy limit of the decision tree model (for our redshift problem) with a training sample size of 25,000 galaxies.\n",
    "\n",
    "The only way we could further improve our model would be to use more features. This might include more colour indices or even the errors associated with the measured flux magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a939c4-6411-4db2-9eaa-599d91a62d1b",
   "metadata": {},
   "source": [
    "![title](pic3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49d5ebc6-603a-4f46-809a-d4e201b29e85",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sdss_galaxy_colors_limz.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7548/2106695260.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Complete the following to make the plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sdss_galaxy_colors_limz.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Get a colour map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'YlOrRd'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sdss_galaxy_colors_limz.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Complete the following to make the plot\n",
    "if __name__ == \"__main__\":\n",
    "    data = np.load('sdss_galaxy_colors_limz.npy')\n",
    "    # Get a colour map\n",
    "    cmap = plt.get_cmap('YlOrRd')\n",
    "\n",
    "    # Define our colour indexes u-g and r-i\n",
    "    u_g = data['u'] - data['g']\n",
    "    r_i = data['r'] - data['i']\n",
    "\n",
    "    # Make a redshift array\n",
    "    redshift = data['redshift']\n",
    "\n",
    "    # Create the plot with plt.scatter\n",
    "    plot = plt.scatter(u_g, r_i, s=0.5, lw=0, c=redshift, cmap=cmap)\n",
    "\n",
    "    cb = plt.colorbar(plot)\n",
    "    cb.set_label('Redshift')\n",
    "\n",
    "    # Define your axis labels and plot title\n",
    "    plt.xlabel('Colour index  u-g')\n",
    "    plt.ylabel('Colour index  r-i')\n",
    "    plt.title('Redshift (colour) u-g versus r-i')\n",
    "\n",
    "    # Set any axis limits\n",
    "    plt.xlim(-0.5, 2.5)\n",
    "    plt.ylim(-0.5, 1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ed2948-5461-45ab-b32a-7e4765b3b18c",
   "metadata": {},
   "source": [
    "## Improving and evaluating our classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e625debb-b136-476b-916f-7d0347af221e",
   "metadata": {},
   "source": [
    " \n",
    "Complete the function accuracy_by_treedepth. The function should return the median difference for both the testing and training data sets for each of the tree depths in depths.\n",
    "\n",
    "accuracy_by_treedepth should take the following arguments:\n",
    "\n",
    "features and targets (as in previous problems);\n",
    "depths: an array of tree depths to be used as the max_depth of the decision tree regressor.\n",
    "Your function should return two lists (or arrays) containing the median_diff values for the predictions made on the training and test sets using the maximum tree depths given by the depths.\n",
    "\n",
    "For example, if depths is [3, 5, 7], then your function should return two lists of length 3. You can choose the size of the split between your testing and training data (if in doubt, 50:50 is fine).\n",
    "\n",
    "We've included code to plot the differences as a function of tree depths. You should take a moment to familiarise yourself with what each line is doing. If your code is working well then your plot should look a bit like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e837aafb-0414-499b-9726-b285384cffd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth with lowest median difference : 21\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# paste your get_features_targets function here\n",
    "def get_features_targets(data):\n",
    "    features = np.zeros((data.shape[0], 4))\n",
    "    features[:, 0] = data['u'] - data['g']\n",
    "    features[:, 1] = data['g'] - data['r']\n",
    "    features[:, 2] = data['r'] - data['i']\n",
    "    features[:, 3] = data['i'] - data['z']\n",
    "    targets =  data['redshift']  \n",
    "    return features, targets\n",
    "  \n",
    "# paste your median_diff function here\n",
    "def median_diff(predicted, actual):\n",
    "    return np.median(abs(predicted-actual))\n",
    "\n",
    "# Complete the following function\n",
    "def accuracy_by_treedepth(features, targets, depths):\n",
    "  # split the data into testing and training sets\n",
    "    split = features.shape[0]//2\n",
    "    train_features = features[:split]\n",
    "    test_features = features[split:]\n",
    "    train_targets = targets[:split]\n",
    "    test_targets = targets[split:]\n",
    "    \n",
    "  # initialise arrays or lists to store the accuracies for the below loop\n",
    "    accuracies_test = []\n",
    "    accuracies_train = []\n",
    "  \n",
    "  # loop through depths\n",
    "    for depth in depths:\n",
    "      # initialize model with the maximum depth. \n",
    "      dtr = DecisionTreeRegressor(max_depth=depth)\n",
    "\n",
    "      # train the model using the training set\n",
    "      dtr.fit(train_features, train_targets)\n",
    "\n",
    "      # get the predictions for the training set and calculate their median_diff\n",
    "      predictions = dtr.predict(train_features)\n",
    "      accuracies_train.append(median_diff(train_targets, predictions))\n",
    "\n",
    "      # get the predictions for the testing set and calculate their median_diff\n",
    "      predictions = dtr.predict(test_features)\n",
    "      accuracies_test.append(median_diff(test_targets, predictions)) \n",
    "\n",
    "    # return the accuracies for the training and testing sets\n",
    "    return accuracies_train, accuracies_test\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  data = np.load('sdss_galaxy_colors.npy')\n",
    "  features, targets = get_features_targets(data)\n",
    "\n",
    "  # Generate several depths to test\n",
    "  tree_depths = [i for i in range(1, 36, 2)]\n",
    "\n",
    "  # Call the function\n",
    "  train_med_diffs, test_med_diffs = accuracy_by_treedepth(features, targets, tree_depths)\n",
    "  print(\"Depth with lowest median difference : {}\".format(tree_depths[test_med_diffs.index(min(test_med_diffs))]))\n",
    "    \n",
    "  # Plot the results\n",
    "  train_plot = plt.plot(tree_depths, train_med_diffs, label='Training set')\n",
    "  test_plot = plt.plot(tree_depths, test_med_diffs, label='Validation set')\n",
    "  plt.xlabel(\"Maximum Tree Depth\")\n",
    "  plt.ylabel(\"Median of Differences\")\n",
    "  plt.legend()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db422f-0daf-4819-9053-f421c44e3fc2",
   "metadata": {},
   "source": [
    "We can see that the accuracy of the decision tree on the training set gets better as we allow the tree to grow to greater depths. In fact, at a depth of 27 our errors goes to zero!\n",
    "\n",
    "Conversly, the accuracy measure of the predictions for the test set gets better initially and then worse at larger tree depths. At a tree depth ~19 the decision tree starts to overfit the data. This means it tries to take into account outliers in the training set and loses its general predictive accuracy.\n",
    "\n",
    "Overfitting is a common problem with decision trees and can be circumvented by adjusting parameters like the tree depth or setting a minimum number of cases at each node. For now, we will set a maximum tree depth of 19 to prevent over-fitting in our redshift problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be27bf-3adf-419d-944c-5a2db55a24ab",
   "metadata": {},
   "source": [
    "## K-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7661231b-3bf6-4808-bf98-100a6451c50d",
   "metadata": {},
   "source": [
    "Your task is to complete the function cross_validate_model. The function takes 4 arguments:\n",
    "\n",
    "model, feaures, and targets as in previous problems;\n",
    "k in our k-fold. This is the number of subsets to train and test.\n",
    "Your function should return a list containing the k median of differences for each of the k folds using median_diff.\n",
    "\n",
    "Note that we have set the max_depth=19 when we initialise the decision tree to prevent the model from overfitting.\n",
    "\n",
    "KFolds usage\n",
    "We have created the KFold object to give you a set of training and testing indices for each of the k runs. It is worth taking a moment to understand this.\n",
    "\n",
    "Specifically, the object is initialised with\n",
    "\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "The n_splits=k passes our desired number of subsets/folds. We want to shuffle the data (as previously explained). The iterator is then used with:\n",
    "\n",
    "for train_indices, test_indices in kf.split(features):\n",
    "The kf.split(features) is an iterator that, for each of the k iterations, returns two arrays of indices to be used with our feature and target arrays, i.e. features[train_indices],targets[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1e60a00-201d-45d4-8a74-759b22abf795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences: 0.018, 0.017, 0.017, 0.017, 0.018, 0.017, 0.017, 0.018, 0.017, 0.018\n",
      "Mean difference: 0.017\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# paste your get_features_targets function here\n",
    "def get_features_targets(data):\n",
    "  features = np.zeros((data.shape[0], 4))\n",
    "  features[:, 0] = data['u'] - data['g']\n",
    "  features[:, 1] = data['g'] - data['r']\n",
    "  features[:, 2] = data['r'] - data['i']\n",
    "  features[:, 3] = data['i'] - data['z']\n",
    "  targets = data['redshift']\n",
    "  return features, targets\n",
    "\n",
    "# paste your median_diff function here\n",
    "def median_diff(predicted, actual):\n",
    "  return np.median(np.abs(predicted - actual))\n",
    "\n",
    "# complete this function\n",
    "def cross_validate_model(model, features, targets, k):\n",
    "  kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "  # initialise a list to collect median_diffs for each iteration of the loop below\n",
    "  diffs = []\n",
    "\n",
    "  for train_indices, test_indices in kf.split(features):\n",
    "    train_features, test_features = features[train_indices], features[test_indices]\n",
    "    train_targets, test_targets = targets[train_indices], targets[test_indices]\n",
    "    \n",
    "    # fit the model for the current set\n",
    "    model.fit(train_features, train_targets)\n",
    "    \n",
    "    # predict using the model\n",
    "    predictions = model.predict(test_features)\n",
    " \n",
    "    # calculate the median_diff from predicted values and append to results array\n",
    "    diffs.append(median_diff(predictions, test_targets))\n",
    " \n",
    "  # return the list with your median difference values\n",
    "  return diffs\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  data = np.load('./sdss_galaxy_colors.npy')\n",
    "  features, targets = get_features_targets(data)\n",
    "\n",
    "  # initialize model with a maximum depth of 19\n",
    "  dtr = DecisionTreeRegressor(max_depth=19)\n",
    "\n",
    "  # call your cross validation function\n",
    "  diffs = cross_validate_model(dtr, features, targets, 10)\n",
    "\n",
    "  # Print the values\n",
    "  print('Differences: {}'.format(', '.join(['{:.3f}'.format(val) for val in diffs])))\n",
    "  print('Mean difference: {:.3f}'.format(np.mean(diffs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fb6d22-f1c3-4cf9-b102-b4cef91f4003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
